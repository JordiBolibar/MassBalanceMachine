{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aa88805730566c5",
   "metadata": {},
   "source": [
    "# MassBalanceMachine Data Processing - Example for Retrieving Training Features for the Norway Region (WGMS)\n",
    "\n",
    "In this notebook, we will demonstrate the data processing workflow of the MassBalanceMachine using an example with glaciological data from Norwegian glaciers. This example will guide you through the data processing pipeline, which retrieves topographical and meteorological features for all points with glaciological surface mass balance observations.\n",
    "\n",
    "We begin by importing some basic libraries along with the ```massbalancemachine``` library. Next, we specify the location where we will store the files for the region of interest (in this case, Iceland). The data used in this example is from the [WGMS database](https://wgms.ch/data_databaseversions/), and we will utilize the specified columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f184536",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T11:53:16.012481Z",
     "start_time": "2024-07-04T11:53:12.644035Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import massbalancemachine as mbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77de54d4",
   "metadata": {},
   "source": [
    "## 1. Load your Target Surface Mass Balance Dataset and Retrieve RGI ID per Stake\n",
    "\n",
    "In this step, we define and load our glaciological data from a region of interest. The WGMS dataset does not include RGI IDs by default, so we need to retrieve them from a glacier outline shapefile provided by the Randolph Glacier Inventory (v6). Each stake is then matched with an RGI ID. The RGI ID is necessary for the MassBalanceMachine to add additional topographical and meteorological features for training stage.\n",
    "\n",
    "**How to Retrieve the Glacier Outlines:** Download the shapefiles for the region of interest from this [link](https://daacdata.apps.nsidc.org/pub/DATASETS/nsidc0770_rgi_v6/). Extract the files and copy the .shp, .prj, and .dbf files in the correct directory so that you can use it with the Jupyter Notebook. Also, make sure you point to the correct directory and files in the next code cell.\n",
    "\n",
    "**Note:** Data records that have an invalid FROM_DATE or TO_DATE, where the day is indicated as 99, are deleted from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b852c00e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T12:16:44.086016Z",
     "start_time": "2024-07-04T12:16:43.924655Z"
    }
   },
   "outputs": [],
   "source": [
    "# Specify the filename of the input file with the raw data\n",
    "target_data_fname = './example_data/norway_wgms_dataset.csv'\n",
    "# Specify the shape filename of the glaciers outline obtained from RGIv6\n",
    "glacier_outline_fname = './example_data/glacier_outlines/08_rgi60_Scandinavia.shp'\n",
    "\n",
    "# Load the target data and the glacier outlines\n",
    "data = pd.read_csv(target_data_fname)\n",
    "glacier_outline = gpd.read_file(glacier_outline_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8327db51d203f25f",
   "metadata": {},
   "source": [
    "### 1.1 Match the Stake Measurements with a RGI ID\n",
    "\n",
    "Based on the location of the stake measurement given by POINT_LAT and POINT_LON, each data record is matched with the RGI ID for the glacier where the stake is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "173deb09497efa60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T11:53:16.232263Z",
     "start_time": "2024-07-04T11:53:16.213848Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the RGI ID for each stake measurement for the region of interest\n",
    "data = mbm.utils.get_rgi(data, glacier_outline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541a28b3c26caa3",
   "metadata": {},
   "source": [
    "Then, we can create a MassBalanceMachine `Dataset`, by using the loaded dataframe for Norway stake data together with the matched RGI IDs, as such: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe9f70525056f75f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T11:53:48.269910Z",
     "start_time": "2024-07-04T11:53:48.263387Z"
    }
   },
   "outputs": [],
   "source": [
    "# Provide the column name for the column that has the RGI IDs for each of the stakes\n",
    "dataset = mbm.Dataset(data=data, data_path='./example_data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045122a5",
   "metadata": {},
   "source": [
    "## 2. Get Topographical Features per Stake Measurement\n",
    "\n",
    "Once we have created a `Dataset`, the first thing we can do is to add topographical data in our dataset. This can be done automatically with the MassBalanceMachine (which calls OGGM) by doing the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ab47703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 15:07:58: oggm.cfg: Reading default parameters from the OGGM `params.cfg` configuration file.\n",
      "2024-07-04 15:07:58: oggm.cfg: Multiprocessing switched OFF according to the parameter file.\n",
      "2024-07-04 15:07:58: oggm.cfg: Multiprocessing: using all available processors (N=12)\n",
      "|  -1.0 B Elapsed Time: 0:00:03                                                \n",
      "2024-07-04 15:08:17: oggm.cfg: PARAMS['border'] changed from `80` to `10`.\n",
      "2024-07-04 15:08:17: oggm.cfg: Multiprocessing switched ON after user settings.\n",
      "2024-07-04 15:08:17: oggm.cfg: PARAMS['continue_on_error'] changed from `False` to `True`.\n",
      "2024-07-04 15:08:17: oggm.workflow: init_glacier_directories from prepro level 3 on 1 glaciers.\n",
      "2024-07-04 15:08:17: oggm.workflow: Execute entity tasks [gdir_from_prepro] on 1 glaciers\n",
      "\u001b[38;2;0;255;0m100%\u001b[39m of 106.3 MiB |######################| Elapsed Time: 0:00:25 Time:  0:00:2502\n",
      "2024-07-04 15:08:43: oggm.workflow: Execute entity tasks [gridded_attributes] on 1 glaciers\n"
     ]
    }
   ],
   "source": [
    "# Specify the topographical features of interest \n",
    "# Please see the OGGM documentation what variables are available: \n",
    "topographical_voi = ['topo', 'aspect', 'slope', 'slope_factor', 'dis_from_border']\n",
    "\n",
    "# Retrieve the topographical features for each of the stake measurement and add them to the dataset\n",
    "dataset.get_topo_features(topographical_voi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9430dbbd531b138",
   "metadata": {},
   "source": [
    "## 3. Get the Meteorological Features per Stake\n",
    "\n",
    "Once we have the topographical data, we can add the necessary climate data for the dataset. This is done by pulling that from ERA5-Land. MassBalanceMachine automatically handles this for the region of interest where the glaciers are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20c314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory and the files of the climate data, that will be matched with the coordinates of the stake data\n",
    "input_era5_fname = '.././regions/iceland/mbm/data/climate/ERA5_monthly_averaged_climate_data.nc'\n",
    "input_gp_fname = '.././regions/iceland/mbm/data/climate/ERA5_geopotential_pressure.nc'\n",
    "\n",
    "# Specify the output filename to save the intermediate results\n",
    "output_climate_fname = 'Iceland_Stake_Data_Climate.csv'\n",
    "\n",
    "# Retrieve the topographical features for each of the stake measurement in the dataset\n",
    "dataset.get_climate_features(output_climate_fname, input_era5_fname, input_gp_fname, 'd3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe4fa9fa2ff6c55",
   "metadata": {},
   "source": [
    "## 4. Transform Data to Monthly Resolution\n",
    "\n",
    "Finally, we need to transform the dataset into a monthly resolution. This will be done in order to perform SMB predictions at a monthly time step, which then will be integrate both in time and space to match the available glaciological and geodetic SMB observations for the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c40243a95f88f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which columns are of interest (vois: variables of interest), please see the metadata file for the ERA5-Land data with all the variable names\n",
    "vois_climate = ['t2m', 'tp', 'sshf', 'slhf', 'ssrd', 'fal', 'str']\n",
    "\n",
    "vois_topo_columns = ['topo', 'aspect', 'slope', 'slope_factor', 'dis_from_border']\n",
    "\n",
    "\n",
    "# Create a dictionary of all the columns in the dataset that match the variables of interest of the ERA5-Land data\n",
    "vois_climate_columns = {voi: [col for col in df.columns.values if re.match(f'{voi}_[a-zA-Z]*', col)] for voi in vois_climate}\n",
    "\n",
    "# Specify the column names for the seasonal (winter and summer) and annual mass balance columns in the dataset\n",
    "smb_column_names = ['ba_stratigraphic', 'bw_stratigraphic', 'bs_stratigraphic']\n",
    "\n",
    "misc_column_names = ['yr']\n",
    "\n",
    "# Specify the output filename to save the intermediate results\n",
    "output_climate_fname = 'Iceland_Stake_Data_Monthly.csv'\n",
    "\n",
    "dataset.convert_to_monthly(output_climate_fname, vois_climate_columns, vois_topo_columns, smb_column_names, misc_column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c4f78689b849e4",
   "metadata": {},
   "source": [
    "Finally, we can take a look at the dataset which will be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119beb4042d90b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dataset.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad10223-a7f7-4179-96ff-51a58a8436ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

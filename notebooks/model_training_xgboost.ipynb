{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "201e61a3dd0c0186",
   "metadata": {},
   "source": [
    "<h1>MassBalanceMachine XGBoost Model Training - Iceland Region Example</h1>\n",
    "<p style='text-align: justify;'>\n",
    "In this notebook, we will simulate the glacier surface mass balance for the Iceland region using a custom <a href='https://xgboost.readthedocs.io/en/stable/'>XGBoost</a> model. The XGBoost model is designed with a custom objective function that generates monthly predictions based on aggregated observational data. We will create an instance of <code>CustomXGBoostRegressor</code> and train it using this custom loss function on the stake data from Iceland, which we have prepared in earlier notebooks. If you haven't already, please review the <a href='https://github.com/ODINN-SciML/MassBalanceMachine/blob/main/notebooks/data_preprocessing.ipynb'>data preprocessing</a> and <a href='https://github.com/ODINN-SciML/MassBalanceMachine/blob/main/notebooks/data_preprocessing.ipynb'>data processing WGMS</a> notebooks for more details.</p>\n",
    "<p style='text-align: justify;'>\n",
    "The workflow includes several key steps:\n",
    "<ol>\n",
    "    <li><strong>Data Loading and Preparation:</strong> A <code>Dataloader</code> object is created to handle the loading of data and the creation of a training and testing split. This object also manages the generation of data splits for cross-validation.</li>\n",
    "    <li><strong>Cross-Validation and Model Training:</strong> Using Scikit-learn's cross-validation techniques, we explore different hyperparameters and train the model on the prepared data splits. This approach ensures a robust evaluation and helps in selecting suitable parameters.</li>\n",
    "    <li><strong>Aggregated Predictions:</strong> After training, we will display the aggregated monthly predictions generated by the model to visualize and analyze the results.</li>\n",
    "    <li><strong>Model Evaluation:</strong> Finally, the model's performance is evaluated on the test set, providing insights into its predictive accuracy for glacier mass balance.</li>\n",
    "</ol></p>"
   ]
  },
  {
   "cell_type": "code",
   "id": "b6c8e565918ac651",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import massbalancemachine as mbm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5b8df3f652285622",
   "metadata": {},
   "source": [
    "data = pd.read_csv('./example_data/iceland/files/iceland_monthly_dataset.csv')\n",
    "display(data)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h2>1. Create the Train and Test Dataset and the Data Splits for Cross Validation</h2>\n",
    "<p style='text-align: justify;'>\n",
    "First, we create a <code>DataLoader</code> object, which generates both training and testing datasets, as well as the data splits required for cross-validation. To conserve memory, the <code>set_train_test_split</code> method returns iterators containing indices for the training and testing datasets. These indices are then used to retrieve the corresponding data for training and testing. Next, the <code>get_cv_split</code> method provides a list indicating the number of folds needed for cross-validation.\n",
    "</p>\n"
   ],
   "id": "885bee2737295b75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a new DataLoader object with the monthly stake data measurements.\n",
    "dataloader = mbm.DataLoader(data=data)\n",
    "# Create a training and testing iterators. The parameters are optional. The default value of test_size is 0.3.\n",
    "train_itr, test_itr = dataloader.set_train_test_split(test_size= 0.3, random_seed=42, shuffle=True)\n",
    "\n",
    "# Get all indices of the training and testing dataset at once from the iterators. Once called, the iterators are empty.\n",
    "train_indices, test_indices = list(train_itr), list(test_itr)\n",
    "\n",
    "# Get the features and targets of the training data for the indices as defined above, that will be used during the cross validation.\n",
    "df_X_train = data.iloc[train_indices]\n",
    "y_train = df_X_train['POINT_BALANCE'].values\n",
    "\n",
    "# Create the cross validation splits based on the training dataset. The default value for the number of splits is 5.\n",
    "splits = dataloader.get_cv_split(n_splits=5)"
   ],
   "id": "d1bf5814ba71dcda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<h2>2. Create a CustomXGBoostRegressor Model</h2>\n",
    "<p style='text-align: justify;'>\n",
    "Next, we define the parameter ranges for each XGBoost parameter. In the subsequent step, we use cross-validation to explore these parameter ranges and select the combination that yields the lowest loss. Additionally, we create a <code>CustomXGBoostRegressor</code> object.\n",
    "</p>"
   ],
   "id": "78b90feda20987d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# For each of the XGBoost parameter, define the grid range\n",
    "parameters = {\n",
    "    'max_depth': [3, 4, 5, 6,],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'gamma': [0, 1]\n",
    "}"
   ],
   "id": "7cf8c2e5ad7303b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "872bc38e1684de43",
   "metadata": {},
   "source": [
    "# Create a CustomXGBoostRegressor instance\n",
    "custom_xgboost = mbm.models.CustomXGBoostRegressor(device=\"cpu\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h2>3. Train the CustomXGBoostRegressor model</h2>",
   "id": "caa230126b8a9ab1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# The default value of num_jobs=-1, meaning all cores will be utilised during fitting the model.\n",
    "# custom_xgboost.gridsearch(parameters=parameters, splits=splits, features=df_X_train, targets=y_train, num_jobs=-1)\n",
    "\n",
    "custom_xgboost.randomsearch(parameters=parameters, n_iter=20, splits=splits, features=df_X_train, targets=y_train, num_jobs=-1)"
   ],
   "id": "dafa807002bf020d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h3>3.1 Show the Predictions per Fold</h3>",
   "id": "bebafd11f8f03bbe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "32f5b4d78e1ca1f3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

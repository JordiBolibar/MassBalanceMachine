{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing of GLAMOS MB data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import massbalancemachine as mbm\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, LineString, Point\n",
    "\n",
    "from scripts.helpers import *\n",
    "from scripts.glamos_preprocess import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_PMB_GLAMOS_raw = '../../../data/GLAMOS/point/raw/'\n",
    "path_PMB_GLAMOS_w_raw = path_PMB_GLAMOS_raw + 'winter/'\n",
    "path_PMB_GLAMOS_a_raw = path_PMB_GLAMOS_raw + 'annual/'\n",
    "\n",
    "path_PMB_GLAMOS_csv = '../../../data/GLAMOS/point/csv/'\n",
    "path_PMB_GLAMOS_csv_w = path_PMB_GLAMOS_csv + 'winter/'\n",
    "path_PMB_GLAMOS_csv_a = path_PMB_GLAMOS_csv + 'annual/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform .dat files to .csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of index stake raw files:\n",
      " ['tortin_annual.dat', 'forno_annual.dat', 'rosatsch_annual.dat', 'petitplanneve_annual.dat', 'corvatsch_annual.dat']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># name</th>\n",
       "      <th>date0</th>\n",
       "      <th>time0</th>\n",
       "      <th>date1</th>\n",
       "      <th>time1</th>\n",
       "      <th>period</th>\n",
       "      <th>date_quality</th>\n",
       "      <th>x_pos</th>\n",
       "      <th>y_pos</th>\n",
       "      <th>z_pos</th>\n",
       "      <th>...</th>\n",
       "      <th>density</th>\n",
       "      <th>density_quality</th>\n",
       "      <th>mb_we</th>\n",
       "      <th>measurement_quality</th>\n",
       "      <th>measurement_type</th>\n",
       "      <th>mb_error</th>\n",
       "      <th>reading_error</th>\n",
       "      <th>density_error</th>\n",
       "      <th>error_evaluation_method</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NMF</td>\n",
       "      <td>19120909</td>\n",
       "      <td>1200</td>\n",
       "      <td>19130920</td>\n",
       "      <td>1200</td>\n",
       "      <td>376.0</td>\n",
       "      <td>0</td>\n",
       "      <td>647166.0</td>\n",
       "      <td>150081.0</td>\n",
       "      <td>2850.0</td>\n",
       "      <td>...</td>\n",
       "      <td>700</td>\n",
       "      <td>4</td>\n",
       "      <td>-1120</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1094</td>\n",
       "      <td>1085</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>glrep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NMG1</td>\n",
       "      <td>19120924</td>\n",
       "      <td>1200</td>\n",
       "      <td>19130920</td>\n",
       "      <td>1200</td>\n",
       "      <td>361.0</td>\n",
       "      <td>0</td>\n",
       "      <td>647089.0</td>\n",
       "      <td>150780.0</td>\n",
       "      <td>2802.0</td>\n",
       "      <td>...</td>\n",
       "      <td>539</td>\n",
       "      <td>6</td>\n",
       "      <td>592</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>873</td>\n",
       "      <td>870</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>glrep</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  # name     date0  time0     date1  time1  period  date_quality     x_pos  \\\n",
       "0    NMF  19120909   1200  19130920   1200   376.0             0  647166.0   \n",
       "1   NMG1  19120924   1200  19130920   1200   361.0             0  647089.0   \n",
       "\n",
       "      y_pos   z_pos  ...  density  density_quality  mb_we  \\\n",
       "0  150081.0  2850.0  ...      700                4  -1120   \n",
       "1  150780.0  2802.0  ...      539                6    592   \n",
       "\n",
       "   measurement_quality  measurement_type  mb_error  reading_error  \\\n",
       "0                    2                 6      1094           1085   \n",
       "1                    4                 6       873            870   \n",
       "\n",
       "   density_error  error_evaluation_method  source  \n",
       "0            134                        0   glrep  \n",
       "1             71                        0   glrep  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all files with pmb (for winter and annual mb):\n",
    "glamosfiles_mb_a, glamosfiles_mb_w = [], []\n",
    "for file in os.listdir(path_PMB_GLAMOS_a_raw):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(path_PMB_GLAMOS_a_raw, file)):\n",
    "        glamosfiles_mb_a.append(file)\n",
    "\n",
    "for file in os.listdir(path_PMB_GLAMOS_w_raw):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(path_PMB_GLAMOS_w_raw, file)):\n",
    "        glamosfiles_mb_w.append(file)\n",
    "\n",
    "print('Examples of index stake raw files:\\n', glamosfiles_mb_a[:5])\n",
    "\n",
    "# Transform all files to csv\n",
    "RUN = True\n",
    "if RUN:\n",
    "    emptyfolder(path_PMB_GLAMOS_csv_a)\n",
    "    emptyfolder(path_PMB_GLAMOS_csv_w)\n",
    "    for file in glamosfiles_mb_a:\n",
    "        fileName = re.split('.dat', file)[0]\n",
    "        processDatFile(fileName, path_PMB_GLAMOS_a_raw, path_PMB_GLAMOS_csv_a)\n",
    "\n",
    "    for file in glamosfiles_mb_w:\n",
    "        fileName = re.split('.dat', file)[0]\n",
    "        processDatFile(fileName, path_PMB_GLAMOS_w_raw, path_PMB_GLAMOS_csv_w)\n",
    "\n",
    "# separate clariden into clariden II and III\n",
    "fileName = 'clariden_annual.csv'\n",
    "clariden_csv_a = pd.read_csv(path_PMB_GLAMOS_csv_a + fileName,\n",
    "                             sep=',',\n",
    "                             header=0,\n",
    "                             encoding='latin-1')\n",
    "clariden_csv_a[clariden_csv_a['# name'] == 'L'].to_csv(path_PMB_GLAMOS_csv_a +\n",
    "                                                       'claridenL_annual.csv',\n",
    "                                                       index=False)\n",
    "clariden_csv_a[clariden_csv_a['# name'] == 'U'].to_csv(path_PMB_GLAMOS_csv_a +\n",
    "                                                       'claridenU_annual.csv',\n",
    "                                                       index=False)\n",
    "\n",
    "fileName = 'clariden_winter.csv'\n",
    "clariden_csv_w = pd.read_csv(path_PMB_GLAMOS_csv_w + fileName,\n",
    "                             sep=',',\n",
    "                             header=0,\n",
    "                             encoding='latin-1')\n",
    "clariden_csv_w[clariden_csv_w['# name'] == 'L'].to_csv(path_PMB_GLAMOS_csv_w +\n",
    "                                                       'claridenL_winter.csv',\n",
    "                                                       index=False)\n",
    "clariden_csv_w[clariden_csv_w['# name'] == 'U'].to_csv(path_PMB_GLAMOS_csv_w +\n",
    "                                                       'claridenU_winter.csv',\n",
    "                                                       index=False)\n",
    "\n",
    "os.remove(path_PMB_GLAMOS_csv_a + 'clariden_annual.csv')\n",
    "os.remove(path_PMB_GLAMOS_csv_w + 'clariden_winter.csv')\n",
    "\n",
    "# Example:\n",
    "fileName = 'aletsch_annual.csv'\n",
    "aletsch_csv = pd.read_csv(path_PMB_GLAMOS_csv_a + fileName,\n",
    "                          sep=',',\n",
    "                          header=0,\n",
    "                          encoding='latin-1')\n",
    "aletsch_csv.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble into one table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_name</th>\n",
       "      <th>sgi-id</th>\n",
       "      <th>rgi_id.v7</th>\n",
       "      <th>Issue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adler</th>\n",
       "      <td>Adler</td>\n",
       "      <td>B56/03</td>\n",
       "      <td>RGI2000-v7.0-G-11-01075</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>albigna</th>\n",
       "      <td>Albigna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RGI2000-v7.0-G-11-02309</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           full_name   sgi-id                rgi_id.v7  Issue\n",
       "short_name                                                   \n",
       "adler          Adler   B56/03  RGI2000-v7.0-G-11-01075  False\n",
       "albigna      Albigna      NaN  RGI2000-v7.0-G-11-02309   True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RGI Ids:\n",
    "# Read rgi ids:\n",
    "path_rgi = '../../../data/GLAMOS/CH_glacier_ids_long.csv'\n",
    "rgi_df = pd.read_csv(path_rgi, sep=',')\n",
    "rgi_df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "rgi_df.sort_values(by='short_name', inplace=True)\n",
    "rgi_df.set_index('short_name', inplace=True)\n",
    "rgi_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af4432b3fc1448c941247fbe3ff7cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summer stakes:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of winter and annual samples: 10688\n",
      "Number of winter samples: 0\n",
      "Number of annual samples: 10688\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>POINT_ID</th>\n",
       "      <th>GLACIER</th>\n",
       "      <th>FROM_DATE</th>\n",
       "      <th>TO_DATE</th>\n",
       "      <th>POINT_LAT</th>\n",
       "      <th>POINT_LON</th>\n",
       "      <th>POINT_ELEVATION</th>\n",
       "      <th>POINT_BALANCE</th>\n",
       "      <th>PERIOD</th>\n",
       "      <th>...</th>\n",
       "      <th>mb_raw</th>\n",
       "      <th>density</th>\n",
       "      <th>density_quality</th>\n",
       "      <th>measurement_quality</th>\n",
       "      <th>measurement_type</th>\n",
       "      <th>mb_error</th>\n",
       "      <th>reading_error</th>\n",
       "      <th>density_error</th>\n",
       "      <th>error_evaluation_method</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>01</td>\n",
       "      <td>oberaar</td>\n",
       "      <td>2002-10-06</td>\n",
       "      <td>2003-10-11</td>\n",
       "      <td>46.538806</td>\n",
       "      <td>8.233237</td>\n",
       "      <td>2389.812633</td>\n",
       "      <td>-6174</td>\n",
       "      <td>annual</td>\n",
       "      <td>...</td>\n",
       "      <td>-686</td>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>45</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>hm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>02</td>\n",
       "      <td>oberaar</td>\n",
       "      <td>2002-10-06</td>\n",
       "      <td>2003-10-11</td>\n",
       "      <td>46.536611</td>\n",
       "      <td>8.225514</td>\n",
       "      <td>2499.825727</td>\n",
       "      <td>-5310</td>\n",
       "      <td>annual</td>\n",
       "      <td>...</td>\n",
       "      <td>-590</td>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>45</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>hm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR POINT_ID  GLACIER   FROM_DATE     TO_DATE  POINT_LAT  POINT_LON  \\\n",
       "0  2003       01  oberaar  2002-10-06  2003-10-11  46.538806   8.233237   \n",
       "1  2003       02  oberaar  2002-10-06  2003-10-11  46.536611   8.225514   \n",
       "\n",
       "   POINT_ELEVATION  POINT_BALANCE  PERIOD  ... mb_raw density  \\\n",
       "0      2389.812633          -6174  annual  ...   -686     900   \n",
       "1      2499.825727          -5310  annual  ...   -590     900   \n",
       "\n",
       "   density_quality  measurement_quality  measurement_type  mb_error  \\\n",
       "0                1                    1                 1       102   \n",
       "1                1                    1                 1        91   \n",
       "\n",
       "   reading_error  density_error  error_evaluation_method  source  \n",
       "0             45             92                        0      hm  \n",
       "1             45             79                        0      hm  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assemble all into one csv file:\n",
    "RUN = True\n",
    "if RUN:\n",
    "    # Annual:\n",
    "    df_all_raw = pd.DataFrame()\n",
    "    for file in tqdm(os.listdir(path_PMB_GLAMOS_csv_a), desc='Summer stakes'):\n",
    "        fileName = re.split('.csv', file)[0]\n",
    "        glacierName = re.split('_', fileName)[0]\n",
    "        df = pd.read_csv(path_PMB_GLAMOS_csv_a + file,\n",
    "                         sep=',',\n",
    "                         header=0,\n",
    "                         encoding='latin-1')\n",
    "        df['glacier'] = glacierName\n",
    "        df['period'] = 'annual'\n",
    "\n",
    "        # Correct years and add hydrol. year:\n",
    "        df_processed = transformDates(df)\n",
    "\n",
    "        # Remove obvious duplicates:\n",
    "        df_processed = df_processed.drop_duplicates()\n",
    "\n",
    "        # Transform to lat/lon system\n",
    "        df_processed = LV03toWGS84(df_processed)\n",
    "\n",
    "        df_all_raw = pd.concat([df_all_raw, df_processed])\n",
    "\n",
    "    # Get the year:\n",
    "    df_all_raw['YEAR'] = df_all_raw['date1'].apply(\n",
    "        lambda x: pd.to_datetime(x).year)\n",
    "\n",
    "    # download all stakes coordinates:\n",
    "    df_all_raw[['glacier', '# name', 'lat', 'lon',\n",
    "                'period']].to_csv(path_PMB_GLAMOS_csv + 'coordinates_all.csv')\n",
    "\n",
    "    # Save all stakes:\n",
    "    df_all_raw.to_csv(path_PMB_GLAMOS_csv + 'point_all.csv')\n",
    "\n",
    "df_all_raw = pd.read_csv(path_PMB_GLAMOS_csv + 'point_all.csv',\n",
    "                         sep=',',\n",
    "                         header=0,\n",
    "                         encoding='latin-1').drop(columns='Unnamed: 0')\n",
    "\n",
    "# Reshape to WGMS format:\n",
    "# re order columns:\n",
    "df_all_raw = df_all_raw[[\n",
    "    'YEAR', '# name', 'glacier', 'date0', 'date1', 'lat', 'lon', 'height',\n",
    "    'mb_we', 'period', 'date_fix0', 'date_fix1', 'time0', 'time1',\n",
    "    'date_quality', 'position_quality', 'mb_raw', 'density', 'density_quality',\n",
    "    'measurement_quality', 'measurement_type', 'mb_error', 'reading_error',\n",
    "    'density_error', 'error_evaluation_method', 'source'\n",
    "]]\n",
    "df_all_raw.rename(columns={\n",
    "    '# name': 'POINT_ID',\n",
    "    'lat': 'POINT_LAT',\n",
    "    'lat': 'POINT_LAT',\n",
    "    'lon': 'POINT_LON',\n",
    "    'height': 'POINT_ELEVATION',\n",
    "    'date0': 'FROM_DATE',\n",
    "    'date1': 'TO_DATE',\n",
    "    'mb_we': 'POINT_BALANCE',\n",
    "    'glacier': 'GLACIER',\n",
    "    'period': 'PERIOD'\n",
    "},\n",
    "                  inplace=True)\n",
    "# remove duplicates:\n",
    "df_all_raw = df_all_raw.drop_duplicates()\n",
    "\n",
    "print('Number of winter and annual samples:', len(df_all_raw))\n",
    "print('Number of winter samples:',\n",
    "      len(df_all_raw[df_all_raw.PERIOD == 'winter']))\n",
    "print('Number of annual samples:',\n",
    "      len(df_all_raw[df_all_raw.PERIOD == 'annual']))\n",
    "\n",
    "df_all_raw.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add RGIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>POINT_ID</th>\n",
       "      <th>GLACIER</th>\n",
       "      <th>FROM_DATE</th>\n",
       "      <th>TO_DATE</th>\n",
       "      <th>POINT_LAT</th>\n",
       "      <th>POINT_LON</th>\n",
       "      <th>POINT_ELEVATION</th>\n",
       "      <th>POINT_BALANCE</th>\n",
       "      <th>PERIOD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>01</td>\n",
       "      <td>oberaar</td>\n",
       "      <td>2002-10-06</td>\n",
       "      <td>2003-10-11</td>\n",
       "      <td>46.538806</td>\n",
       "      <td>8.233237</td>\n",
       "      <td>2389.812633</td>\n",
       "      <td>-6174</td>\n",
       "      <td>annual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>02</td>\n",
       "      <td>oberaar</td>\n",
       "      <td>2002-10-06</td>\n",
       "      <td>2003-10-11</td>\n",
       "      <td>46.536611</td>\n",
       "      <td>8.225514</td>\n",
       "      <td>2499.825727</td>\n",
       "      <td>-5310</td>\n",
       "      <td>annual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>03</td>\n",
       "      <td>oberaar</td>\n",
       "      <td>2002-10-06</td>\n",
       "      <td>2003-10-11</td>\n",
       "      <td>46.532136</td>\n",
       "      <td>8.207734</td>\n",
       "      <td>2679.854419</td>\n",
       "      <td>-4320</td>\n",
       "      <td>annual</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR POINT_ID  GLACIER   FROM_DATE     TO_DATE  POINT_LAT  POINT_LON  \\\n",
       "0  2003       01  oberaar  2002-10-06  2003-10-11  46.538806   8.233237   \n",
       "1  2003       02  oberaar  2002-10-06  2003-10-11  46.536611   8.225514   \n",
       "2  2003       03  oberaar  2002-10-06  2003-10-11  46.532136   8.207734   \n",
       "\n",
       "   POINT_ELEVATION  POINT_BALANCE  PERIOD  \n",
       "0      2389.812633          -6174  annual  \n",
       "1      2499.825727          -5310  annual  \n",
       "2      2679.854419          -4320  annual  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep important features:\n",
    "df_pmb = df_all_raw[[\n",
    "    'YEAR',\n",
    "    'POINT_ID',\n",
    "    'GLACIER',\n",
    "    'FROM_DATE',\n",
    "    'TO_DATE',\n",
    "    'POINT_LAT',\n",
    "    'POINT_LON',\n",
    "    'POINT_ELEVATION',\n",
    "    'POINT_BALANCE',\n",
    "    'PERIOD',\n",
    "]]\n",
    "df_pmb.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291d3e79a9114e7aaee8d7c6faca9102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1325 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add RGIs:\n",
    "# Specify the shape filename of the glaciers outline obtained from RGIv6\n",
    "glacier_outline_fname = '../../../data/GLAMOS/nsidc0770_11.rgi60.CentralEurope/11_rgi60_CentralEurope.shp'\n",
    "\n",
    "# Load the target data and the glacier outlines\n",
    "glacier_outline = gpd.read_file(glacier_outline_fname)\n",
    "\n",
    "# Add RGI IDs through intersection with shapefiles:\n",
    "df_pmb = mbm.utils.get_rgi(data=df_pmb, glacier_outlines=glacier_outline)\n",
    "\n",
    "# Add RGIs without intersections (by finding the closest polygon):\n",
    "# for points where polygon intersection is NaN (about a 1000)\n",
    "no_match_df = df_pmb[df_pmb.RGIId.isna()]\n",
    "geometry = [\n",
    "    Point(lon, lat)\n",
    "    for lon, lat in zip(no_match_df[\"POINT_LON\"], no_match_df[\"POINT_LAT\"])\n",
    "]\n",
    "points_gdf = gpd.GeoDataFrame(no_match_df,\n",
    "                              geometry=geometry,\n",
    "                              crs=glacier_outline.crs)\n",
    "for index in tqdm(no_match_df.index):\n",
    "    point = points_gdf.loc[index]['geometry']\n",
    "    polygon_index = glacier_outline.distance(point).sort_values().index[0]\n",
    "    closest_rgi = glacier_outline.loc[polygon_index].RGIId\n",
    "    df_pmb.at[index, 'RGIId'] = closest_rgi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adler': ['RGI60-11.02764'],\n",
       " 'albigna': ['RGI60-11.02299', 'RGI60-11.02285', 'RGI60-11.02282'],\n",
       " 'aletsch': ['RGI60-11.01450'],\n",
       " 'allalin': ['RGI60-11.02704'],\n",
       " 'arolla': ['RGI60-11.02810'],\n",
       " 'basodino': ['RGI60-11.01987'],\n",
       " 'bertol': ['RGI60-11.02779'],\n",
       " 'blauschnee': ['RGI60-11.00638'],\n",
       " 'cantun': ['RGI60-11.02268'],\n",
       " 'chessjen': ['RGI60-11.02674'],\n",
       " 'claridenL': ['RGI60-11.00817'],\n",
       " 'claridenU': ['RGI60-11.00843'],\n",
       " 'corbassiere': ['RGI60-11.02766'],\n",
       " 'corvatsch': ['RGI60-11.01962'],\n",
       " 'damma': ['RGI60-11.01246'],\n",
       " 'diablerets': ['RGI60-11.02261'],\n",
       " 'diavolezza': ['RGI60-11.02013'],\n",
       " 'err': ['RGI60-11.01516', 'RGI60-11.01549'],\n",
       " 'findelen': ['RGI60-11.02773'],\n",
       " 'forno': ['RGI60-11.02245'],\n",
       " 'gietro': ['RGI60-11.02774'],\n",
       " 'gorner': ['RGI60-11.02822'],\n",
       " 'gries': ['RGI60-11.01876', 'RGI60-11.02441'],\n",
       " 'gurschen': ['RGI60-11.01344'],\n",
       " 'hohlaub': ['RGI60-11.02679'],\n",
       " 'joeri': ['RGI60-11.01063'],\n",
       " 'limmern': ['RGI60-11.00918', 'RGI60-11.00915'],\n",
       " 'misaun': ['RGI60-11.01945'],\n",
       " 'morteratsch': ['RGI60-11.01946'],\n",
       " 'murtel': ['RGI60-11.02024'],\n",
       " 'oberaar': ['RGI60-11.01509'],\n",
       " 'ofental': ['RGI60-11.02735', 'RGI60-11.02714'],\n",
       " 'orny': ['RGI60-11.02740', 'RGI60-11.02775'],\n",
       " 'otemma': ['RGI60-11.02801'],\n",
       " 'pers': ['RGI60-11.01946'],\n",
       " 'petitplanneve': ['RGI60-11.02369'],\n",
       " 'pizol': ['RGI60-11.00638'],\n",
       " 'plainemorte': ['RGI60-11.02072'],\n",
       " 'planneve': ['RGI60-11.02448'],\n",
       " 'plattalva': ['RGI60-11.00892', 'RGI60-11.00901'],\n",
       " 'rhone': ['RGI60-11.01238'],\n",
       " 'rosatsch': ['RGI60-11.01847'],\n",
       " 'sanktanna': ['RGI60-11.01367'],\n",
       " 'sardona': ['RGI60-11.00689'],\n",
       " 'schwarzbach': ['RGI60-11.01376'],\n",
       " 'schwarzberg': ['RGI60-11.02746'],\n",
       " 'segnes': ['RGI60-11.00695'],\n",
       " 'sexrouge': ['RGI60-11.02244'],\n",
       " 'silvretta': ['RGI60-11.00804', 'RGI60-11.00735', 'RGI60-11.00833'],\n",
       " 'taelliboden': ['RGI60-11.02792'],\n",
       " 'tiefen': ['RGI60-11.01296'],\n",
       " 'tortin': ['RGI60-11.02600'],\n",
       " 'tsanfleuron': ['RGI60-11.02249'],\n",
       " 'unteraar': ['RGI60-11.01328'],\n",
       " 'untgrindelwald': ['RGI60-11.01346'],\n",
       " 'vorab': ['RGI60-11.00752'],\n",
       " 'witenwasseren': ['RGI60-11.01522']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at identified RGIs per glacier:\n",
    "rgiids6 = df_pmb[['GLACIER',\n",
    "                  'RGIId']].sort_values(by='GLACIER').drop_duplicates()\n",
    "rgis = {}\n",
    "for gl in rgiids6.GLACIER.unique():\n",
    "    rgis[gl] = list(rgiids6[rgiids6.GLACIER == gl].RGIId)\n",
    "rgis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adler': ['RGI60-11.02764'],\n",
       " 'albigna': ['RGI60-11.02285'],\n",
       " 'aletsch': ['RGI60-11.01450'],\n",
       " 'allalin': ['RGI60-11.02704'],\n",
       " 'arolla': ['RGI60-11.02810'],\n",
       " 'basodino': ['RGI60-11.01987'],\n",
       " 'bertol': ['RGI60-11.02779'],\n",
       " 'blauschnee': ['RGI60-11.00638'],\n",
       " 'cantun': ['RGI60-11.02268'],\n",
       " 'chessjen': ['RGI60-11.02674'],\n",
       " 'claridenL': ['RGI60-11.00817'],\n",
       " 'claridenU': ['RGI60-11.00843'],\n",
       " 'corbassiere': ['RGI60-11.02766'],\n",
       " 'corvatsch': ['RGI60-11.01962'],\n",
       " 'damma': ['RGI60-11.01246'],\n",
       " 'diablerets': ['RGI60-11.02261'],\n",
       " 'diavolezza': ['RGI60-11.02013'],\n",
       " 'err': ['RGI60-11.01516'],\n",
       " 'findelen': ['RGI60-11.02773'],\n",
       " 'forno': ['RGI60-11.02245'],\n",
       " 'gietro': ['RGI60-11.02774'],\n",
       " 'gorner': ['RGI60-11.02822'],\n",
       " 'gries': ['RGI60-11.01876'],\n",
       " 'gurschen': ['RGI60-11.01344'],\n",
       " 'hohlaub': ['RGI60-11.02679'],\n",
       " 'joeri': ['RGI60-11.01063'],\n",
       " 'limmern': ['RGI60-11.00918'],\n",
       " 'misaun': ['RGI60-11.01945'],\n",
       " 'morteratsch': ['RGI60-11.01946'],\n",
       " 'murtel': ['RGI60-11.02024'],\n",
       " 'oberaar': ['RGI60-11.01509'],\n",
       " 'orny': ['RGI60-11.02775'],\n",
       " 'otemma': ['RGI60-11.02801'],\n",
       " 'pers': ['RGI60-11.01946'],\n",
       " 'petitplanneve': ['RGI60-11.02369'],\n",
       " 'pizol': ['RGI60-11.00638'],\n",
       " 'plainemorte': ['RGI60-11.02072'],\n",
       " 'planneve': ['RGI60-11.02448'],\n",
       " 'plattalva': ['RGI60-11.00892'],\n",
       " 'rhone': ['RGI60-11.01238'],\n",
       " 'rosatsch': ['RGI60-11.01847'],\n",
       " 'sanktanna': ['RGI60-11.01367'],\n",
       " 'sardona': ['RGI60-11.00689'],\n",
       " 'schwarzbach': ['RGI60-11.01376'],\n",
       " 'schwarzberg': ['RGI60-11.02746'],\n",
       " 'segnes': ['RGI60-11.00695'],\n",
       " 'sexrouge': ['RGI60-11.02244'],\n",
       " 'silvretta': ['RGI60-11.00804'],\n",
       " 'taelliboden': ['RGI60-11.02792'],\n",
       " 'tiefen': ['RGI60-11.01296'],\n",
       " 'tortin': ['RGI60-11.02600'],\n",
       " 'tsanfleuron': ['RGI60-11.02249'],\n",
       " 'unteraar': ['RGI60-11.01328'],\n",
       " 'untgrindelwald': ['RGI60-11.01346'],\n",
       " 'vorab': ['RGI60-11.00752'],\n",
       " 'witenwasseren': ['RGI60-11.01522']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manual pre-processing and removal of errors:\n",
    "# Silvretta: weird outlier coordinate\n",
    "df_pmb_clean = df_pmb.copy()\n",
    "index_outlier = df_pmb_clean[(df_pmb_clean.GLACIER == 'silvretta')\n",
    "                             & (df_pmb_clean.POINT_LAT > 46.9)].index\n",
    "df_pmb_clean.drop(index_outlier, inplace=True)\n",
    "\n",
    "# and remove the stake that is on the neighbouring glacier:\n",
    "index_outlier = df_pmb_clean[(df_pmb_clean.GLACIER == 'silvretta')\n",
    "                             & (df_pmb_clean.RGIId != 'RGI60-11.00804')].index\n",
    "df_pmb_clean.drop(index_outlier, inplace=True)\n",
    "\n",
    "# Albigna: different rgis, remove stakes that are for two neighbouring glaciers:\n",
    "index_outlier = df_pmb_clean[(df_pmb_clean.GLACIER == 'albigna')\n",
    "                             & (df_pmb_clean.RGIId != 'RGI60-11.02285')].index\n",
    "df_pmb_clean.drop(index_outlier, inplace=True)\n",
    "\n",
    "# Err glacier: remove stakes that are on neighbouring glacier:\n",
    "index_outlier = df_pmb_clean[(df_pmb_clean.GLACIER == 'err')\n",
    "                             & (df_pmb_clean.RGIId != 'RGI60-11.01516')].index\n",
    "df_pmb_clean.drop(index_outlier, inplace=True)\n",
    "\n",
    "# Gries: weird outlier coordinate\n",
    "index_outlier = df_pmb_clean[(df_pmb_clean.GLACIER == 'gries')\n",
    "                             & (df_pmb_clean.RGIId != 'RGI60-11.01876')].index\n",
    "df_pmb_clean.drop(index_outlier, inplace=True)\n",
    "\n",
    "# Limmern: three stakes on neighbouring glacier\n",
    "index_outlier = df_pmb_clean[(df_pmb_clean.GLACIER == 'limmern')\n",
    "                             & (df_pmb_clean.RGIId != 'RGI60-11.00918')].index\n",
    "df_pmb_clean.drop(index_outlier, inplace=True)\n",
    "\n",
    "# Offental: on no RGI v6 outline\n",
    "df_pmb_clean = df_pmb_clean[df_pmb_clean.GLACIER != 'ofental']\n",
    "\n",
    "# Orny: change to correct RGIId\n",
    "index_outlier = df_pmb_clean[(df_pmb_clean.GLACIER == 'orny')].index\n",
    "for i in index_outlier:\n",
    "    df_pmb_clean.at[i, 'RGIId'] = 'RGI60-11.02775'\n",
    "\n",
    "# Plattalva: change to correct RGIId\n",
    "index_outlier = df_pmb_clean[(df_pmb_clean.GLACIER == 'plattalva')].index\n",
    "for i in index_outlier:\n",
    "    df_pmb_clean.at[i, 'RGIId'] = 'RGI60-11.00892'\n",
    "    \n",
    "# Look at identified RGIs per glacier:\n",
    "rgiids6 = df_pmb_clean[['GLACIER',\n",
    "                  'RGIId']].sort_values(by='GLACIER').drop_duplicates()\n",
    "rgis = {}\n",
    "for gl in rgiids6.GLACIER.unique():\n",
    "    rgis[gl] = list(rgiids6[rgiids6.GLACIER == gl].RGIId)\n",
    "rgis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv:\n",
    "df_pmb_clean.to_csv(path_PMB_GLAMOS_csv + 'CH_wgms_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add topographical features from OGGM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Dataset.Dataset at 0x7f5dc0760160>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Provide the column name for the column that has the RGI IDs for each of the stakes\n",
    "dataset = mbm.Dataset(data=df_pmb,\n",
    "                      region_name='CH',\n",
    "                      data_path=path_PMB_GLAMOS_csv)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 09:46:43: oggm.cfg: Reading default parameters from the OGGM `params.cfg` configuration file.\n",
      "2024-07-31 09:46:43: oggm.cfg: Multiprocessing switched OFF according to the parameter file.\n",
      "2024-07-31 09:46:43: oggm.cfg: Multiprocessing: using all available processors (N=32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/vmarijn/scratch/MassBalanceMachine/regions/Switzerland/GLAMOS_preprocessing.ipynb Cell 18\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bachtzack01.ethz.ch/home/vmarijn/scratch/MassBalanceMachine/regions/Switzerland/GLAMOS_preprocessing.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m voi_topographical \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39maspect\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mslope\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bachtzack01.ethz.ch/home/vmarijn/scratch/MassBalanceMachine/regions/Switzerland/GLAMOS_preprocessing.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Retrieve the topographical features for each stake measurement and add them to the dataset\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bachtzack01.ethz.ch/home/vmarijn/scratch/MassBalanceMachine/regions/Switzerland/GLAMOS_preprocessing.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m dataset\u001b[39m.\u001b[39;49mget_topo_features(vois\u001b[39m=\u001b[39;49mvoi_topographical)\n",
      "File \u001b[0;32m/scratch-3/vmarijn/MassBalanceMachine/massbalancemachine/data_processing/Dataset.py:52\u001b[0m, in \u001b[0;36mDataset.get_topo_features\u001b[0;34m(self, vois)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39mFetches all the topographical data, for a list of variables of interest, using OGGM for the specified RGI IDs\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \n\u001b[1;32m     48\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[39m    vois (list[str]): A string containing the topographical variables of interest\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m output_fname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_output_filename(\u001b[39m\"\u001b[39m\u001b[39mtopographical_features\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 52\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m get_topographical_features(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata, output_fname, vois,\n\u001b[1;32m     53\u001b[0m                                        \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mRGIIds)\n",
      "File \u001b[0;32m/scratch-3/vmarijn/MassBalanceMachine/massbalancemachine/data_processing/get_topo_data.py:46\u001b[0m, in \u001b[0;36mget_topographical_features\u001b[0;34m(df, output_fname, voi, rgi_ids)\u001b[0m\n\u001b[1;32m     43\u001b[0m rgi_ids_list \u001b[39m=\u001b[39m _get_unique_rgi_ids(rgi_ids)\n\u001b[1;32m     45\u001b[0m \u001b[39m# Initialize the OGGM Config\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m _initialize_oggm_config()\n\u001b[1;32m     48\u001b[0m \u001b[39m# Initialize the OGGM Glacier Directory, given the available RGI IDs\u001b[39;00m\n\u001b[1;32m     49\u001b[0m glacier_directories \u001b[39m=\u001b[39m _initialize_glacier_directories(rgi_ids_list)\n",
      "File \u001b[0;32m/scratch-3/vmarijn/MassBalanceMachine/massbalancemachine/data_processing/get_topo_data.py:91\u001b[0m, in \u001b[0;36m_initialize_oggm_config\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_initialize_oggm_config\u001b[39m():\n\u001b[1;32m     90\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Initialize OGGM configuration.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m     cfg\u001b[39m.\u001b[39;49minitialize(logging_level\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mWARNING\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     92\u001b[0m     cfg\u001b[39m.\u001b[39mPARAMS[\u001b[39m\"\u001b[39m\u001b[39mborder\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m     93\u001b[0m     cfg\u001b[39m.\u001b[39mPARAMS[\u001b[39m\"\u001b[39m\u001b[39muse_multiprocessing\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/MassBalanceMachine/lib/python3.10/site-packages/oggm/cfg.py:653\u001b[0m, in \u001b[0;36minitialize\u001b[0;34m(file, logging_level, params, future)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[39m# Trigger a one time check of the hash file\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39moggm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_dl_verify_data\n\u001b[0;32m--> 653\u001b[0m get_dl_verify_data(\u001b[39m'\u001b[39;49m\u001b[39mdummy_section\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    655\u001b[0m \u001b[39m# OK\u001b[39;00m\n\u001b[1;32m    656\u001b[0m PARAMS\u001b[39m.\u001b[39mdo_log \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/MassBalanceMachine/lib/python3.10/site-packages/oggm/utils/_downloads.py:260\u001b[0m, in \u001b[0;36mget_dl_verify_data\u001b[0;34m(section)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[1;32m    259\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 260\u001b[0m     data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_hdf(verify_file_path, key\u001b[39m=\u001b[39;49msection)\n\u001b[1;32m    261\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m    262\u001b[0m     data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n",
      "File \u001b[0;32m~/mambaforge/envs/MassBalanceMachine/lib/python3.10/site-packages/pandas/io/pytables.py:426\u001b[0m, in \u001b[0;36mread_hdf\u001b[0;34m(path_or_buf, key, mode, errors, where, start, stop, columns, iterator, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m exists:\n\u001b[1;32m    424\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFile \u001b[39m\u001b[39m{\u001b[39;00mpath_or_buf\u001b[39m}\u001b[39;00m\u001b[39m does not exist\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 426\u001b[0m store \u001b[39m=\u001b[39m HDFStore(path_or_buf, mode\u001b[39m=\u001b[39;49mmode, errors\u001b[39m=\u001b[39;49merrors, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    427\u001b[0m \u001b[39m# can't auto open/close if we are using an iterator\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[39m# so delegate to the iterator\u001b[39;00m\n\u001b[1;32m    429\u001b[0m auto_close \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/MassBalanceMachine/lib/python3.10/site-packages/pandas/io/pytables.py:566\u001b[0m, in \u001b[0;36mHDFStore.__init__\u001b[0;34m(self, path, mode, complevel, complib, fletcher32, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mformat\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m    564\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mformat is not a defined argument for HDFStore\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 566\u001b[0m tables \u001b[39m=\u001b[39m import_optional_dependency(\u001b[39m\"\u001b[39;49m\u001b[39mtables\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    568\u001b[0m \u001b[39mif\u001b[39;00m complib \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m complib \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m tables\u001b[39m.\u001b[39mfilters\u001b[39m.\u001b[39mall_complibs:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    570\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcomplib only supports \u001b[39m\u001b[39m{\u001b[39;00mtables\u001b[39m.\u001b[39mfilters\u001b[39m.\u001b[39mall_complibs\u001b[39m}\u001b[39;00m\u001b[39m compression.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m     )\n",
      "File \u001b[0;32m~/mambaforge/envs/MassBalanceMachine/lib/python3.10/site-packages/pandas/compat/_optional.py:135\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    130\u001b[0m msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    131\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing optional dependency \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00minstall_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m{\u001b[39;00mextra\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    132\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUse pip or conda to install \u001b[39m\u001b[39m{\u001b[39;00minstall_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    133\u001b[0m )\n\u001b[1;32m    134\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(name)\n\u001b[1;32m    136\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/mambaforge/envs/MassBalanceMachine/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/MassBalanceMachine/lib/python3.10/site-packages/tables/__init__.py:44\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mBlosc2 library not found. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     41\u001b[0m                        \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mI looked for \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(blosc2_search_paths)\u001b[39m}\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[39m# Necessary imports to get versions stored on the cython extension\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutilsextension\u001b[39;00m \u001b[39mimport\u001b[39;00m get_hdf5_version \u001b[39mas\u001b[39;00m _get_hdf5_version\n\u001b[1;32m     46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_version\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n\u001b[1;32m     48\u001b[0m hdf5_version \u001b[39m=\u001b[39m _get_hdf5_version()\n",
      "File \u001b[0;32m~/mambaforge/envs/MassBalanceMachine/lib/python3.10/site-packages/tables/utilsextension.pyx:1\u001b[0m, in \u001b[0;36minit tables.utilsextension\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "# Specify the topographical features of interest\n",
    "# Please see the OGGM documentation what variables are available: https://oggm.org/tutorials/stable/notebooks/10minutes/machine_learning.html ('topo', 'slope_factor', 'dis_from_border')\n",
    "voi_topographical = ['aspect', 'slope']\n",
    "\n",
    "# Retrieve the topographical features for each stake measurement and add them to the dataset\n",
    "dataset.get_topo_features(vois=voi_topographical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MassBalanceMachine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
